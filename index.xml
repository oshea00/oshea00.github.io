<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>MikesBlog</title>
    <link>https://oshea00.github.io/</link>
    <description>Recent content on MikesBlog</description>
    <generator>Hugo -- 0.156.0</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 22 Feb 2026 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://oshea00.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AI Adoption - Systems Model</title>
      <link>https://oshea00.github.io/posts/interactive-hype-cycle/</link>
      <pubDate>Sun, 22 Feb 2026 00:00:00 +0000</pubDate>
      <guid>https://oshea00.github.io/posts/interactive-hype-cycle/</guid>
      <description>&lt;html lang=&#34;en&#34;&gt;
&lt;head&gt;
&lt;meta charset=&#34;UTF-8&#34;&gt;
&lt;meta name=&#34;viewport&#34; content=&#34;width=device-width, initial-scale=1.0&#34;&gt;
&lt;style&gt;
  @import url(&#39;https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:wght@300;400;600&amp;family=IBM+Plex+Sans:wght@300;400;600&amp;display=swap&#39;);

  :root {
    --bg: #0a0e14;
    --panel: #111820;
    --border: #1e2d3d;
    --accent: #00b4d8;
    --accent2: #f77f00;
    --accent3: #06d6a0;
    --accent4: #ef476f;
    --stock-color: #00b4d8;
    --flow-color: #f77f00;
    --trigger-color: #ef476f;
    --text: #cdd9e5;
    --muted: #808c96;
  }

  * { margin: 0; padding: 0; box-sizing: border-box; }

  body {
    background: var(--bg);
    color: var(--text);
    font-family: &#39;IBM Plex Sans&#39;, monospace;
    min-height: 100vh;
    overflow-x: hidden;
  }

  header {
    padding: 32px 48px 20px;
    border-bottom: 1px solid var(--border);
    display: flex;
    flex-direction: column;
    gap: 14px;
  }

 .header-top {
  display: flex;
  align-items: flex-end;
  justify-content: space-between;
  }

  h1 {
    font-family: &#39;IBM Plex Mono&#39;, monospace;
    font-size: 13px;
    font-weight: 600;
    letter-spacing: 0.15em;
    text-transform: uppercase;
    color: var(--accent);
  }

  .subtitle {
    font-size: 14px;
    font-weight: 600;
    color: var(--text);
    letter-spacing: 0.08em;
    margin-top: 4px;
  }

  .infosubtitle {
    font-size: 12px;
    font-weight: 600;
    color: var(--muted);
    letter-spacing: 0.08em;
    margin-top: 4px;
  }

  .legend {
    display: flex;
    gap: 28px;
    font-size: 11px;
    font-family: &#39;IBM Plex Mono&#39;, monospace;
    flex-wrap: nowrap;
  }

  .legend-item {
    display: flex;
    align-items: center;
    gap: 8px;
  }

  .legend-dot {
    width: 10px;
    height: 10px;
    border-radius: 2px;
  }

  .diagram-container {
    padding: 40px 48px;
    position: relative;
  }

  svg {
    width: 100%;
    height: auto;
    overflow: visible;
  }

   
  .stock {
    cursor: pointer;
    transition: all 0.2s;
  }
  .stock:hover .stock-rect { filter: brightness(1.3); }
  .stock-rect {
    rx: 4;
    fill: #0d1f2d;
    stroke: var(--stock-color);
    stroke-width: 1.5;
    transition: all 0.2s;
  }
  .stock-label {
    fill: var(--stock-color);
    font-family: &#39;IBM Plex Mono&#39;, monospace;
    font-size: 11px;
    font-weight: 600;
    letter-spacing: 0.05em;
    text-transform: uppercase;
  }
  .stock-sublabel {
    fill: #5c8a9e;
    font-family: &#39;IBM Plex Sans&#39;, sans-serif;
    font-size: 9.5px;
  }

   
  .flow-path {
    fill: none;
    stroke: var(--flow-color);
    stroke-width: 1.5;
    stroke-dasharray: 6 3;
    opacity: 0.7;
  }
  .flow-label {
    fill: var(--flow-color);
    font-family: &#39;IBM Plex Mono&#39;, monospace;
    font-size: 10px;
    letter-spacing: 0.04em;
  }

   
  .trigger-circle {
    fill: #1a0a10;
    stroke: var(--trigger-color);
    stroke-width: 1.5;
  }
  .trigger-label {
    fill: var(--trigger-color);
    font-family: &#39;IBM Plex Mono&#39;, monospace;
    font-size: 9.6px;
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.04em;
  }
  .trigger-path {
    fill: none;
    stroke: var(--trigger-color);
    stroke-width: 1;
    stroke-dasharray: 3 4;
    opacity: 0.5;
  }

   
  .reinforce-path {
    fill: none;
    stroke: var(--accent3);
    stroke-width: 1.5;
    stroke-dasharray: 8 3;
    opacity: 0.5;
  }
  .reinforce-label {
    fill: var(--accent3);
    font-family: &#39;IBM Plex Mono&#39;, monospace;
    font-size: 10px;
  }

   
  #info-panel {
    position: fixed;
    right: 40px;
    top: 50%;
    transform: translateY(-50%);
    width: 240px;
    background: var(--panel);
    border: 1px solid var(--border);
    border-left: 3px solid var(--accent);
    padding: 20px;
    opacity: 0;
    transition: opacity 0.3s;
    pointer-events: none;
  }
  #info-panel.visible { opacity: 1; }
  #info-title {
    font-family: &#39;IBM Plex Mono&#39;, monospace;
    font-size: 11px;
    font-weight: 600;
    color: var(--accent);
    text-transform: uppercase;
    letter-spacing: 0.1em;
    margin-bottom: 10px;
  }
  #info-body {
    font-size: 12px;
    line-height: 1.7;
    color: var(--text);
  }
  #info-type {
    font-size: 9px;
    color: var(--muted);
    text-transform: uppercase;
    letter-spacing: 0.1em;
    margin-top: 10px;
  }

  .note {
    margin-top: 16px;
    padding: 0 48px 32px;
    font-size: 14px;
    font-weight: 600;
    color: var(--text);
    font-family: &#39;IBM Plex Mono&#39;, monospace;
    letter-spacing: 0.04em;
  }

   
  marker path { }

  .loop-badge {
    font-family: &#39;IBM Plex Mono&#39;, monospace;
    font-size: 10px;
    letter-spacing: 0.05em;
  }
&lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;

&lt;header&gt;
  &lt;div&gt;
    &lt;div class=&#34;subtitle&#34;&gt;Stocks, Flows &amp;amp; Impediments to Rapid Diffusion · 2022–present&lt;/div&gt;
  &lt;/div&gt;
&lt;div class=&#34;infosubtitle&#34;&gt;
  ↓ Click any stock or resistance node for detail &amp;nbsp;|&amp;nbsp; Flows (dashed orange) show rates of change &amp;nbsp;|&amp;nbsp; Resistance nodes (red) act as governors limiting flow rates
&lt;/div&gt;
  &lt;div class=&#34;legend&#34;&gt;
    &lt;div class=&#34;legend-item&#34;&gt;&lt;div class=&#34;legend-dot&#34; style=&#34;background:#00b4d8&#34;&gt;&lt;/div&gt;&lt;span style=&#34;color:#00b4d8&#34;&gt;STOCK&lt;/span&gt;&lt;/div&gt;
    &lt;div class=&#34;legend-item&#34;&gt;&lt;div class=&#34;legend-dot&#34; style=&#34;background:#f77f00&#34;&gt;&lt;/div&gt;&lt;span style=&#34;color:#f77f00&#34;&gt;FLOW&lt;/span&gt;&lt;/div&gt;
    &lt;div class=&#34;legend-item&#34;&gt;&lt;div class=&#34;legend-dot&#34; style=&#34;background:#ef476f&#34;&gt;&lt;/div&gt;&lt;span style=&#34;color:#ef476f&#34;&gt;RESISTANCE&lt;/span&gt;&lt;/div&gt;
    &lt;div class=&#34;legend-item&#34;&gt;&lt;div class=&#34;legend-dot&#34; style=&#34;background:#06d6a0&#34;&gt;&lt;/div&gt;&lt;span style=&#34;color:#06d6a0&#34;&gt;REINFORCING LOOP&lt;/span&gt;&lt;/div&gt;
  &lt;/div&gt;

&lt;/header&gt;

&lt;div class=&#34;diagram-container&#34;&gt;
&lt;svg viewBox=&#34;0 0 960 680&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;
  &lt;defs&gt;
    &lt;marker id=&#34;arrow-flow&#34; markerWidth=&#34;8&#34; markerHeight=&#34;8&#34; refX=&#34;6&#34; refY=&#34;3&#34; orient=&#34;auto&#34;&gt;
      &lt;path d=&#34;M0,0 L0,6 L8,3 z&#34; fill=&#34;#f77f00&#34; opacity=&#34;0.8&#34;/&gt;
    &lt;/marker&gt;
    &lt;marker id=&#34;arrow-trigger&#34; markerWidth=&#34;7&#34; markerHeight=&#34;7&#34; refX=&#34;5&#34; refY=&#34;3&#34; orient=&#34;auto&#34;&gt;
      &lt;path d=&#34;M0,0 L0,6 L7,3 z&#34; fill=&#34;#ef476f&#34; opacity=&#34;0.6&#34;/&gt;
    &lt;/marker&gt;
    &lt;marker id=&#34;arrow-reinforce&#34; markerWidth=&#34;8&#34; markerHeight=&#34;8&#34; refX=&#34;6&#34; refY=&#34;3&#34; orient=&#34;auto&#34;&gt;
      &lt;path d=&#34;M0,0 L0,6 L8,3 z&#34; fill=&#34;#06d6a0&#34; opacity=&#34;0.7&#34;/&gt;
    &lt;/marker&gt;
    &lt;filter id=&#34;glow&#34;&gt;
      &lt;feGaussianBlur stdDeviation=&#34;3&#34; result=&#34;coloredBlur&#34;/&gt;
      &lt;feMerge&gt;&lt;feMergeNode in=&#34;coloredBlur&#34;/&gt;&lt;feMergeNode in=&#34;SourceGraphic&#34;/&gt;&lt;/feMerge&gt;
    &lt;/filter&gt;
  &lt;/defs&gt;

  

  
  &lt;g class=&#34;stock&#34; onclick=&#34;showInfo(&#39;AI Capability Stock&#39;, &#39;The accumulated body of AI models, tools, APIs, and research. Grows continuously via R&amp;D investment. Currently very high and accelerating — this stock is NOT the bottleneck.&#39;, &#39;STOCK&#39;)&#34;&gt;
    &lt;rect class=&#34;stock-rect&#34; x=&#34;370&#34; y=&#34;30&#34; width=&#34;220&#34; height=&#34;64&#34; rx=&#34;4&#34;/&gt;
    &lt;text class=&#34;stock-label&#34; x=&#34;480&#34; y=&#34;56&#34; text-anchor=&#34;middle&#34;&gt;AI Capability&lt;/text&gt;
    &lt;text class=&#34;stock-sublabel&#34; x=&#34;480&#34; y=&#34;72&#34; text-anchor=&#34;middle&#34;&gt;Models, APIs, Tools, Research&lt;/text&gt;
    &lt;text class=&#34;stock-sublabel&#34; x=&#34;480&#34; y=&#34;85&#34; text-anchor=&#34;middle&#34; style=&#34;fill:#06d6a0&#34;&gt;▲ High &amp;amp; Accelerating&lt;/text&gt;
  &lt;/g&gt;

  
  &lt;g class=&#34;stock&#34; onclick=&#34;showInfo(&#39;Workforce Readiness Stock&#39;, &#39;The aggregate skill, familiarity, and comfort workers have with AI tools. Drains slowly from retirement/attrition, fills slowly through training and hands-on use. Enormous inertia — most organizations are still in early accumulation phase.&#39;, &#39;STOCK&#39;)&#34;&gt;
    &lt;rect class=&#34;stock-rect&#34; x=&#34;40&#34; y=&#34;240&#34; width=&#34;200&#34; height=&#34;64&#34; rx=&#34;4&#34;/&gt;
    &lt;text class=&#34;stock-label&#34; x=&#34;140&#34; y=&#34;266&#34; text-anchor=&#34;middle&#34;&gt;Workforce&lt;/text&gt;
    &lt;text class=&#34;stock-label&#34; x=&#34;140&#34; y=&#34;280&#34; text-anchor=&#34;middle&#34;&gt;Readiness&lt;/text&gt;
    &lt;text class=&#34;stock-sublabel&#34; x=&#34;140&#34; y=&#34;295&#34; text-anchor=&#34;middle&#34;&gt;Skills, Habits, Comfort&lt;/text&gt;
  &lt;/g&gt;

  
  &lt;g class=&#34;stock&#34; onclick=&#34;showInfo(&#39;Institutional Trust Stock&#39;, &#39;The degree to which organizations formally trust and authorize AI in decision-making workflows. Builds slowly via proven pilots and audits. Erodes quickly from high-profile failures. Currently low-to-medium across most sectors.&#39;, &#39;STOCK&#39;)&#34;&gt;
    &lt;rect class=&#34;stock-rect&#34; x=&#34;270&#34; y=&#34;340&#34; width=&#34;200&#34; height=&#34;64&#34; rx=&#34;4&#34;/&gt;
    &lt;text class=&#34;stock-label&#34; x=&#34;370&#34; y=&#34;366&#34; text-anchor=&#34;middle&#34;&gt;Institutional&lt;/text&gt;
    &lt;text class=&#34;stock-label&#34; x=&#34;370&#34; y=&#34;380&#34; text-anchor=&#34;middle&#34;&gt;Trust&lt;/text&gt;
    &lt;text class=&#34;stock-sublabel&#34; x=&#34;370&#34; y=&#34;395&#34; text-anchor=&#34;middle&#34;&gt;Authorization &amp;amp; Confidence&lt;/text&gt;
  &lt;/g&gt;

  
  &lt;g class=&#34;stock&#34; onclick=&#34;showInfo(&#39;Regulatory Clarity Stock&#39;, &#39;The degree to which governments and standards bodies have defined legal frameworks for AI use. Currently very low globally. Without clear rules, legal risk deters enterprise adoption especially in healthcare, finance, and law.&#39;, &#39;STOCK&#39;)&#34;&gt;
    &lt;rect class=&#34;stock-rect&#34; x=&#34;500&#34; y=&#34;340&#34; width=&#34;200&#34; height=&#34;64&#34; rx=&#34;4&#34;/&gt;
    &lt;text class=&#34;stock-label&#34; x=&#34;600&#34; y=&#34;366&#34; text-anchor=&#34;middle&#34;&gt;Regulatory&lt;/text&gt;
    &lt;text class=&#34;stock-label&#34; x=&#34;600&#34; y=&#34;380&#34; text-anchor=&#34;middle&#34;&gt;Clarity&lt;/text&gt;
    &lt;text class=&#34;stock-sublabel&#34; x=&#34;600&#34; y=&#34;395&#34; text-anchor=&#34;middle&#34;&gt;Legal Frameworks &amp;amp; Standards&lt;/text&gt;
    &lt;text class=&#34;stock-sublabel&#34; x=&#34;600&#34; y=&#34;403&#34; text-anchor=&#34;middle&#34; style=&#34;fill:#ef476f&#34;&gt;▼ Currently Low&lt;/text&gt;
  &lt;/g&gt;

  
  &lt;g class=&#34;stock&#34; onclick=&#34;showInfo(&#39;AI Adoption Stock&#39;, &#39;The actual integration of AI into real workflows across individuals, enterprises, and institutions. This is the output stock. It grows only as fast as the upstream stocks allow — workforce readiness, trust, and regulatory clarity all act as rate limiters.&#39;, &#39;STOCK — PRIMARY OUTPUT&#39;)&#34;&gt;
    &lt;rect class=&#34;stock-rect&#34; x=&#34;370&#34; y=&#34;540&#34; width=&#34;220&#34; height=&#34;64&#34; rx=&#34;4&#34; style=&#34;stroke-width:2.5&#34;/&gt;
    &lt;text class=&#34;stock-label&#34; x=&#34;480&#34; y=&#34;566&#34; text-anchor=&#34;middle&#34; style=&#34;font-size:13px&#34;&gt;AI Adoption&lt;/text&gt;
    &lt;text class=&#34;stock-sublabel&#34; x=&#34;480&#34; y=&#34;582&#34; text-anchor=&#34;middle&#34;&gt;Real Workflow Integration&lt;/text&gt;
    &lt;text class=&#34;stock-sublabel&#34; x=&#34;480&#34; y=&#34;595&#34; text-anchor=&#34;middle&#34; style=&#34;fill:#f77f00&#34;&gt;◈ Primary Output Stock&lt;/text&gt;
  &lt;/g&gt;

  
  &lt;g class=&#34;stock&#34; onclick=&#34;showInfo(&#39;Infrastructure Stock&#39;, &#39;Compute availability, cloud AI services, enterprise APIs, integration tooling. Growing fast but unevenly distributed. SMBs and developing markets lag significantly. Cost per inference still prohibitive for many use cases.&#39;, &#39;STOCK&#39;)&#34;&gt;
    &lt;rect class=&#34;stock-rect&#34; x=&#34;720&#34; y=&#34;240&#34; width=&#34;200&#34; height=&#34;64&#34; rx=&#34;4&#34;/&gt;
    &lt;text class=&#34;stock-label&#34; x=&#34;820&#34; y=&#34;266&#34; text-anchor=&#34;middle&#34;&gt;Infrastructure&lt;/text&gt;
    &lt;text class=&#34;stock-sublabel&#34; x=&#34;820&#34; y=&#34;282&#34; text-anchor=&#34;middle&#34;&gt;Compute, APIs, Tooling&lt;/text&gt;
    &lt;text class=&#34;stock-sublabel&#34; x=&#34;820&#34; y=&#34;295&#34; text-anchor=&#34;middle&#34; style=&#34;fill:#06d6a0&#34;&gt;▲ Growing (uneven)&lt;/text&gt;
  &lt;/g&gt;

  

  
  &lt;path class=&#34;flow-path&#34; d=&#34;M 480 94 L 480 120 Q 480 140 460 150 L 240 270&#34; 
        marker-end=&#34;url(#arrow-flow)&#34;/&gt;
  &lt;text class=&#34;flow-label&#34; x=&#34;305&#34; y=&#34;185&#34;&gt;capability exposure&lt;/text&gt;
  &lt;text class=&#34;flow-label&#34; x=&#34;305&#34; y=&#34;196&#34;&gt;→ training inflow&lt;/text&gt;

  
  &lt;path class=&#34;flow-path&#34; d=&#34;M 590 62 L 700 220 L 720 255&#34; 
        marker-end=&#34;url(#arrow-flow)&#34;/&gt;
  &lt;text class=&#34;flow-label&#34; x=&#34;670&#34; y=&#34;185&#34;&gt;API/service&lt;/text&gt;
  &lt;text class=&#34;flow-label&#34; x=&#34;670&#34; y=&#34;196&#34;&gt;buildout&lt;/text&gt;

  
  &lt;path class=&#34;flow-path&#34; d=&#34;M 210 292 L 290 360&#34; 
        marker-end=&#34;url(#arrow-flow)&#34;/&gt;
  &lt;text class=&#34;flow-label&#34; x=&#34;215&#34; y=&#34;338&#34;&gt;demonstrated&lt;/text&gt;
  &lt;text class=&#34;flow-label&#34; x=&#34;215&#34; y=&#34;349&#34;&gt;competence&lt;/text&gt;

  
  &lt;path class=&#34;flow-path&#34; d=&#34;M 760 304 L 680 350&#34; 
        marker-end=&#34;url(#arrow-flow)&#34;/&gt;
  &lt;text class=&#34;flow-label&#34; x=&#34;728&#34; y=&#34;335&#34;&gt;use cases&lt;/text&gt;
  &lt;text class=&#34;flow-label&#34; x=&#34;728&#34; y=&#34;346&#34;&gt;define rules&lt;/text&gt;

  
  &lt;path class=&#34;flow-path&#34; d=&#34;M 420 404 L 440 540&#34; 
        marker-end=&#34;url(#arrow-flow)&#34;/&gt;
  &lt;text class=&#34;flow-label&#34; x=&#34;378&#34; y=&#34;482&#34;&gt;authorized&lt;/text&gt;
  &lt;text class=&#34;flow-label&#34; x=&#34;378&#34; y=&#34;493&#34;&gt;deployment&lt;/text&gt;

  
  &lt;path class=&#34;flow-path&#34; d=&#34;M 550 404 L 530 540&#34; 
        marker-end=&#34;url(#arrow-flow)&#34;/&gt;
  &lt;text class=&#34;flow-label&#34; x=&#34;556&#34; y=&#34;478&#34;&gt;legal&lt;/text&gt;
  &lt;text class=&#34;flow-label&#34; x=&#34;556&#34; y=&#34;489&#34;&gt;clearance&lt;/text&gt;

  

  
  &lt;g onclick=&#34;showInfo(&#39;Resistance: Loss Aversion&#39;, &#39;Workers fear displacement more than they value productivity gains. This is deeply psychological and slows voluntary skill acquisition. Unions and professional bodies amplify this resistance. Acts directly on the Workforce Readiness inflow.&#39;, &#39;RESISTANCE TRIGGER&#39;)&#34;&gt;
    &lt;ellipse class=&#34;trigger-circle&#34; cx=&#34;90&#34; cy=&#34;170&#34; rx=&#34;70&#34; ry=&#34;28&#34;/&gt;
    &lt;text class=&#34;trigger-label&#34; x=&#34;90&#34; y=&#34;166&#34; text-anchor=&#34;middle&#34;&gt;Job Threat&lt;/text&gt;
    &lt;text class=&#34;trigger-label&#34; x=&#34;90&#34; y=&#34;178&#34; text-anchor=&#34;middle&#34;&gt;Perception&lt;/text&gt;
  &lt;/g&gt;
  &lt;path class=&#34;trigger-path&#34; d=&#34;M 90 198 L 110 242&#34; marker-end=&#34;url(#arrow-trigger)&#34;/&gt;
  &lt;text style=&#34;fill:#ef476f; font-size:10px; font-family:&#39;IBM Plex Mono&#39;&#34; x=&#34;45&#34; y=&#34;222&#34;&gt;⊖ slows&lt;/text&gt;

  
  &lt;g onclick=&#34;showInfo(&#39;Resistance: High-Profile Failures&#39;, &#39;Publicized AI errors — hallucinated legal citations, medical mistakes, biased hiring decisions — erode institutional trust rapidly. A single major failure can drain months of accumulated trust-building. Acts as a negative shock to the Institutional Trust stock.&#39;, &#39;RESISTANCE TRIGGER&#39;)&#34;&gt;
    &lt;ellipse class=&#34;trigger-circle&#34; cx=&#34;175&#34; cy=&#34;460&#34; rx=&#34;78&#34; ry=&#34;28&#34;/&gt;
    &lt;text class=&#34;trigger-label&#34; x=&#34;175&#34; y=&#34;456&#34; text-anchor=&#34;middle&#34;&gt;Publicized AI&lt;/text&gt;
    &lt;text class=&#34;trigger-label&#34; x=&#34;175&#34; y=&#34;468&#34; text-anchor=&#34;middle&#34;&gt;Failures&lt;/text&gt;
  &lt;/g&gt;
  &lt;path class=&#34;trigger-path&#34; d=&#34;M 253 460 L 290 395&#34; marker-end=&#34;url(#arrow-trigger)&#34;/&gt;
  &lt;text style=&#34;fill:#ef476f; font-size:10px; font-family:&#39;IBM Plex Mono&#39;&#34; x=&#34;220&#34; y=&#34;435&#34;&gt;⊖ erodes trust&lt;/text&gt;

  
  &lt;g onclick=&#34;showInfo(&#39;Resistance: Regulatory Uncertainty&#39;, &#39;Without clear rules, legal and compliance teams apply maximum caution. This is especially acute in healthcare (HIPAA), finance (SEC/FINRA), and law. The absence of a rule is itself a blocker — it forces organizations to self-regulate conservatively.&#39;, &#39;RESISTANCE TRIGGER&#39;)&#34;&gt;
    &lt;ellipse class=&#34;trigger-circle&#34; cx=&#34;760&#34; cy=&#34;460&#34; rx=&#34;78&#34; ry=&#34;28&#34;/&gt;
    &lt;text class=&#34;trigger-label&#34; x=&#34;760&#34; y=&#34;456&#34; text-anchor=&#34;middle&#34;&gt;Legal / Liability&lt;/text&gt;
    &lt;text class=&#34;trigger-label&#34; x=&#34;760&#34; y=&#34;468&#34; text-anchor=&#34;middle&#34;&gt;Uncertainty&lt;/text&gt;
  &lt;/g&gt;
  &lt;path class=&#34;trigger-path&#34; d=&#34;M 700 460 L 680 405&#34; marker-end=&#34;url(#arrow-trigger)&#34;/&gt;
  &lt;text style=&#34;fill:#ef476f; font-size:10px; font-family:&#39;IBM Plex Mono&#39;&#34; x=&#34;690&#34; y=&#34;430&#34;&gt;⊖ chills&lt;/text&gt;
  &lt;text style=&#34;fill:#ef476f; font-size:9px; font-family:&#39;IBM Plex Mono&#39;&#34; x=&#34;690&#34; y=&#34;451&#34;&gt;adoption&lt;/text&gt;

  
  &lt;g onclick=&#34;showInfo(&#39;Resistance: Integration Complexity&#39;, &#39;Existing enterprise systems (ERP, CRM, legacy databases) were not designed for AI integration. The technical debt of existing stocks of software infrastructure creates a slow, expensive on-ramp. Most organizations underestimate this by 3-5x.&#39;, &#39;RESISTANCE TRIGGER&#39;)&#34;&gt;
    &lt;ellipse class=&#34;trigger-circle&#34; cx=&#34;870&#34; cy=&#34;170&#34; rx=&#34;76&#34; ry=&#34;28&#34;/&gt;
    &lt;text class=&#34;trigger-label&#34; x=&#34;870&#34; y=&#34;166&#34; text-anchor=&#34;middle&#34;&gt;Legacy System&lt;/text&gt;
    &lt;text class=&#34;trigger-label&#34; x=&#34;870&#34; y=&#34;178&#34; text-anchor=&#34;middle&#34;&gt;Complexity&lt;/text&gt;
  &lt;/g&gt;
  &lt;path class=&#34;trigger-path&#34; d=&#34;M 830 196 L 820 242&#34; marker-end=&#34;url(#arrow-trigger)&#34;/&gt;
  &lt;text style=&#34;fill:#ef476f; font-size:10px; font-family:&#39;IBM Plex Mono&#39;&#34; x=&#34;820&#34; y=&#34;224&#34;&gt;⊖ slows&lt;/text&gt;

  
  
  &lt;path class=&#34;reinforce-path&#34; 
        d=&#34;M 480 604 Q 480 650 600 650 Q 740 650 740 550 Q 740 430 680 400&#34; 
        marker-end=&#34;url(#arrow-reinforce)&#34;/&gt;
  &lt;text class=&#34;reinforce-label&#34; x=&#34;650&#34; y=&#34;645&#34;&gt;R+ Early adopter success&lt;/text&gt;
  &lt;text class=&#34;reinforce-label&#34; x=&#34;650&#34; y=&#34;656&#34;&gt;builds proof cases → trust&lt;/text&gt;

  

  
  &lt;rect x=&#34;10&#34; y=&#34;10&#34; width=&#34;340&#34; height=&#34;20&#34; rx=&#34;2&#34; fill=&#34;none&#34; stroke=&#34;#1e2d3d&#34; stroke-width=&#34;1&#34;/&gt;
  &lt;text style=&#34;fill:#d0dfe9; font-family:&#39;IBM Plex Mono&#39;; font-size:12px; letter-spacing:0.08em&#34; x=&#34;18&#34; y=&#34;24&#34;&gt;SYSTEM BOUNDARY: Enterprise AI Adoption&lt;/text&gt;

  
  &lt;text style=&#34;fill:#ef476f; font-family:&#39;IBM Plex Mono&#39;; font-size:10px; letter-spacing:0.05em&#34; x=&#34;40&#34; y=&#34;650&#34;&gt;B− Balancing loops (resistance nodes) create natural governor on adoption rate&lt;/text&gt;

&lt;/svg&gt;
&lt;/div&gt;

&lt;div id=&#34;info-panel&#34;&gt;
  &lt;div id=&#34;info-title&#34;&gt;—&lt;/div&gt;
  &lt;div id=&#34;info-body&#34;&gt;—&lt;/div&gt;
  &lt;div id=&#34;info-type&#34;&gt;—&lt;/div&gt;
&lt;/div&gt;

&lt;script&gt;
function showInfo(title, body, type) {
  document.getElementById(&#39;info-title&#39;).textContent = title;
  document.getElementById(&#39;info-body&#39;).textContent = body;
  document.getElementById(&#39;info-type&#39;).textContent = &#39;■ &#39; + type;
  
  const panel = document.getElementById(&#39;info-panel&#39;);
  panel.style.borderLeftColor = type.includes(&#39;RESISTANCE&#39;) ? &#39;#ef476f&#39; : 
                                 type.includes(&#39;OUTPUT&#39;) ? &#39;#f77f00&#39; : &#39;#00b4d8&#39;;
  panel.classList.add(&#39;visible&#39;);
}

document.addEventListener(&#39;click&#39;, function(e) {
  if (!e.target.closest(&#39;.stock&#39;) &amp;&amp; !e.target.closest(&#39;g[onclick]&#39;)) {
    document.getElementById(&#39;info-panel&#39;).classList.remove(&#39;visible&#39;);
  }
});
&lt;/script&gt;
&lt;/body&gt;</description>
    </item>
    <item>
      <title>Agentic Orchestration is Not a Moat</title>
      <link>https://oshea00.github.io/posts/agentic-orchestration-not-a-moat/</link>
      <pubDate>Sat, 14 Feb 2026 00:00:00 +0000</pubDate>
      <guid>https://oshea00.github.io/posts/agentic-orchestration-not-a-moat/</guid>
      <description>&lt;figure class=&#34;align-center &#34;&gt;
    &lt;img loading=&#34;lazy&#34; src=&#34;images/cutecomputerarmy.png#center&#34;/&gt; 
&lt;/figure&gt;

&lt;p&gt;The recent explosion of social media frenzy over agentic orchestration tools such as OpenClaw and GasTown, vibe-coded and quickly released into the wild, is yet another symptom of overhyped expectations related to generative AI models. If it takes three weeks to go viral after a few months of vibe coding, it&amp;rsquo;s a trivial solution, and it will be copied, relentlessly, and everyone will move on to something else&amp;ndash;not sure what that will be.&lt;/p&gt;</description>
    </item>
    <item>
      <title>MCP Tools Integration Hands-On</title>
      <link>https://oshea00.github.io/posts/chat-with-tools/</link>
      <pubDate>Sun, 04 Jan 2026 00:00:00 +0000</pubDate>
      <guid>https://oshea00.github.io/posts/chat-with-tools/</guid>
      <description>&lt;figure class=&#34;align-center &#34;&gt;
    &lt;img loading=&#34;lazy&#34; src=&#34;images/cutecomputerchat.png#center&#34;/&gt; 
&lt;/figure&gt;

&lt;p&gt;The Model Context Protocol (MCP) allows large language models (LLMs) to call external tools while answering user prompts. In practice, most people use chat-based tools like Claude or Copilot rather than interacting directly with model APIs, and these tools make it easy to configure MCP servers without writing code. That said, if you want to connect your own data sources or custom functions as MCP tools, or connect your code to MCP tools, you’ll have to roll up your sleeves and do some hands-on work.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI Cloud Interactive Hype Cycle 2025</title>
      <link>https://oshea00.github.io/posts/ai-adoption-systems/</link>
      <pubDate>Mon, 29 Sep 2025 00:00:00 +0000</pubDate>
      <guid>https://oshea00.github.io/posts/ai-adoption-systems/</guid>
      <description>&lt;html lang=&#34;en&#34;&gt;
&lt;head&gt;
    &lt;meta charset=&#34;UTF-8&#34;&gt;
    &lt;meta name=&#34;viewport&#34; content=&#34;width=device-width, initial-scale=1.0&#34;&gt;
    &lt;style&gt;
         
        #hype-cycle-widget {
            font-family: -apple-system, BlinkMacSystemFont, &#39;Segoe UI&#39;, Roboto, sans-serif;
            background: white;
            width: 100%;
            max-width: 1400px;
            margin: 0 auto;
        }

        #hype-cycle-widget * {
            box-sizing: border-box;
        }

        #hype-cycle-widget .hype-container {
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(10px);
            border-radius: 0;
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.1);
            overflow: hidden;
        }

        #hype-cycle-widget .hype-header {
            background: linear-gradient(135deg, #2c3e50 0%, #34495e 100%);
            color: white;
            padding: 30px;
            text-align: center;
        }

        #hype-cycle-widget .hype-header h1 {
            font-size: 2.5rem;
            font-weight: 700;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);
        }

        #hype-cycle-widget .hype-header p {
            font-size: 1.1rem;
            opacity: 0.9;
            margin: 5px 0;
        }

        #hype-cycle-widget .hype-main-content {
            display: flex;
            flex-direction: column;
            gap: 30px;
            padding: 30px;
        }

        #hype-cycle-widget .hype-chart-section {
            background: white;
            border-radius: 15px;
            padding: 20px;
            box-shadow: 0 10px 25px rgba(0, 0, 0, 0.1);
            position: relative;
        }

        #hype-cycle-widget .hype-chart-container {
            position: relative;
            width: 100%;
            height: 500px;
            background: #f8f9fa;
            border-radius: 10px;
            overflow: hidden;
        }

        #hype-cycle-widget .hype-curve {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            pointer-events: none;
        }

        #hype-cycle-widget .hype-table-section {
            background: white;
            border-radius: 15px;
            padding: 20px;
            box-shadow: 0 10px 25px rgba(0, 0, 0, 0.1);
        }

        #hype-cycle-widget .hype-controls {
            display: flex;
            gap: 15px;
            margin-bottom: 20px;
            flex-wrap: wrap;
        }

        #hype-cycle-widget .hype-search-box,
        #hype-cycle-widget .hype-filter-select {
            padding: 12px 16px;
            border: 2px solid #e1e5e9;
            border-radius: 10px;
            font-size: 14px;
            transition: all 0.3s ease;
            background: white;
        }

        #hype-cycle-widget .hype-search-box:focus,
        #hype-cycle-widget .hype-filter-select:focus {
            outline: none;
            border-color: #667eea;
            box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1);
        }

        #hype-cycle-widget .hype-search-box {
            flex: 1;
            min-width: 200px;
        }

        #hype-cycle-widget .hype-filter-select {
            min-width: 150px;
        }

        #hype-cycle-widget .hype-table-container {
            overflow: auto;
            max-height: 400px;
            border-radius: 10px;
            border: 1px solid #e1e5e9;
        }

        #hype-cycle-widget table {
            width: 100%;
            border-collapse: collapse;
            background: white;
        }

        #hype-cycle-widget th {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 15px 12px;
            text-align: left;
            font-weight: 600;
            cursor: pointer;
            position: sticky;
            top: 0;
            z-index: 10;
            transition: all 0.2s ease;
        }

        #hype-cycle-widget th:hover {
            background: linear-gradient(135deg, #5a6fd8 0%, #6a4190 100%);
        }

        #hype-cycle-widget td {
            padding: 12px;
            border-bottom: 1px solid #e1e5e9;
            vertical-align: top;
        }

        #hype-cycle-widget tr:hover {
            background: #f8f9ff;
        }

        #hype-cycle-widget .tech-name {
            font-weight: 600;
            color: #2c3e50;
        }

        #hype-cycle-widget .position {
            font-weight: 500;
            padding: 4px 8px;
            border-radius: 6px;
            font-size: 0.9rem;
        }

        #hype-cycle-widget .innovation-trigger { background: #e8f5e8; color: #2d5a2d; }
        #hype-cycle-widget .peak-expectations { background: #fff3cd; color: #856404; }
        #hype-cycle-widget .trough-disillusionment { background: #f8d7da; color: #721c24; }
        #hype-cycle-widget .slope-enlightenment { background: #d4edda; color: #155724; }
        #hype-cycle-widget .plateau-productivity { background: #d1ecf1; color: #0c5460; }

        #hype-cycle-widget .time-badge {
            display: inline-block;
            padding: 4px 8px;
            border-radius: 12px;
            font-size: 0.8rem;
            font-weight: 500;
        }

        #hype-cycle-widget .time-lt2 { background: #e3f2fd; color: #1565c0; }
        #hype-cycle-widget .time-2-5 { background: #e8f5e8; color: #2e7d32; }
        #hype-cycle-widget .time-5-10 { background: #fff3e0; color: #ef6c00; }
        #hype-cycle-widget .time-gt10 { background: #fce4ec; color: #c2185b; }
        #hype-cycle-widget .time-obsolete { background: #f3e5f5; color: #7b1fa2; }

        #hype-cycle-widget .analysis-cell {
            max-width: 300px;
            line-height: 1.4;
            font-size: 0.9rem;
        }

        #hype-cycle-widget .hype-tooltip {
            position: absolute;
            background: rgba(0, 0, 0, 0.9);
            color: white;
            padding: 12px 16px;
            border-radius: 8px;
            font-size: 14px;
            max-width: 300px;
            z-index: 1000;
            opacity: 0;
            transition: opacity 0.3s ease;
            pointer-events: none;
            box-shadow: 0 8px 25px rgba(0, 0, 0, 0.3);
        }

        #hype-cycle-widget .hype-tooltip.show {
            opacity: 1;
        }

        #hype-cycle-widget .tech-dot {
            position: absolute;
            width: 12px;
            height: 12px;
            border-radius: 50%;
            cursor: pointer;
            transition: all 0.2s ease;
            z-index: 5;
        }

        #hype-cycle-widget .tech-dot:hover {
            transform: scale(1.5);
            z-index: 6;
        }

        #hype-cycle-widget .tech-dot.innovation-trigger { background: #4caf50; }
        #hype-cycle-widget .tech-dot.peak-expectations { background: #ff9800; }
        #hype-cycle-widget .tech-dot.trough-disillusionment { background: #f44336; }
        #hype-cycle-widget .tech-dot.slope-enlightenment { background: #2196f3; }
        #hype-cycle-widget .tech-dot.plateau-productivity { background: #9c27b0; }

        #hype-cycle-widget .sort-icon {
            display: inline-block;
            margin-left: 5px;
            opacity: 0.5;
        }

        @media (max-width: 768px) {
            #hype-cycle-widget .hype-header h1 {
                font-size: 1.8rem;
            }
            
            #hype-cycle-widget .hype-controls {
                flex-direction: column;
            }
            
            #hype-cycle-widget .hype-search-box,
            #hype-cycle-widget .hype-filter-select {
                width: 100%;
            }
        }
    &lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
    
    &lt;div id=&#34;hype-cycle-widget&#34;&gt;
        &lt;div class=&#34;hype-container&#34;&gt;
            &lt;div class=&#34;hype-header&#34;&gt;
                &lt;p style=&#34;font-size: 1rem; opacity: 0.8; margin-top: 10px;&#34;&gt;Based on Gartner Hype Cycle for Cloud Platform Services, 2025&lt;/p&gt;</description>
    </item>
    <item>
      <title>Model Context Protocol (MCP) Best Practices</title>
      <link>https://oshea00.github.io/posts/mcp-practices/</link>
      <pubDate>Mon, 29 Sep 2025 00:00:00 +0000</pubDate>
      <guid>https://oshea00.github.io/posts/mcp-practices/</guid>
      <description>&lt;figure class=&#34;align-center &#34;&gt;
    &lt;img loading=&#34;lazy&#34; src=&#34;images/cuteMCP.png#center&#34;/&gt; 
&lt;/figure&gt;

&lt;p&gt;&lt;em&gt;As we integrate services and data APIs into agentic AI solutions, interest is growing in how the Model Context Protocol (MCP) can standardize the way tools expose their capabilities to agents. With that in mind, I’ve assembled—yes, with the help of AI—a survey of key topics and resources related to MCP.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;MCP is an &lt;strong&gt;open standard&lt;/strong&gt; (launched by Anthropic in Nov 2024) for exposing data sources, tools, and “resources” to AI agents via a uniform interface.
It is designed to replace the ad-hoc “one-off connector per tool/agent” pattern, simplifying how LLM-based agents integrate with live systems. [1]&lt;/p&gt;</description>
    </item>
    <item>
      <title>A2A Doesn&#39;t need AI Agents</title>
      <link>https://oshea00.github.io/posts/a2a-thoughts/</link>
      <pubDate>Sun, 28 Sep 2025 00:00:00 +0000</pubDate>
      <guid>https://oshea00.github.io/posts/a2a-thoughts/</guid>
      <description>&lt;figure class=&#34;align-center &#34;&gt;
    &lt;img loading=&#34;lazy&#34; src=&#34;images/cutecomputeragentstalking.png#center&#34;/&gt; 
&lt;/figure&gt;

&lt;p&gt;&lt;em&gt;Is this just distributed computing re-packaged for AI?&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;what-is-a2a-without-ai-agents&#34;&gt;What is A2A Without AI Agents?&lt;/h2&gt;
&lt;p&gt;I got into a debate with Gemini recently about Agent-To-Agent protocol (A2A). I said I thought it was a retread of existing distributed computing technologies like Service Discovery, Mesh, CORBA, etc. Perhaps Gemini took it personally, as Google (Gemini&amp;rsquo;s Creator) had &lt;a href=&#34;https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/&#34;&gt;announced A2A in April&lt;/a&gt;, and Gemini got a little &amp;ldquo;gushy&amp;rdquo; on how it was &amp;ldquo;a revolutionary new idea.&amp;rdquo; Also, perhaps &amp;ldquo;debate&amp;rdquo; is too strong a word. And I might want to consider getting out more often.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Building a Hybrid Summary Evaluation Framework</title>
      <link>https://oshea00.github.io/posts/summary-evals/</link>
      <pubDate>Sun, 14 Sep 2025 00:00:00 +0000</pubDate>
      <guid>https://oshea00.github.io/posts/summary-evals/</guid>
      <description>&lt;p&gt;&lt;figure class=&#34;align-center &#34;&gt;
    &lt;img loading=&#34;lazy&#34; src=&#34;images/cutecomputereditor.png#center&#34;/&gt; 
&lt;/figure&gt;

&lt;em&gt;Combining deterministic NLP with LLM-as-Judge for robust evaluation&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;summary-evaluation-challenges&#34;&gt;Summary Evaluation Challenges&lt;/h2&gt;
&lt;p&gt;Summary evaluation metrics sometimes fall short in capturing the qualities most relevant to assessing summary quality. Traditional machine learning for natural language processing (NLP)
has covered a lot of ground in this area. Widely used measures such as ROUGE focus on surface-level token overlap and n-gram matches. While effective for evaluating lexical similarity, these approaches offer limited insight into aspects such as factual accuracy or semantic completeness [1].&lt;/p&gt;</description>
    </item>
    <item>
      <title>Vibecoding an Agentic Coder - Part 2</title>
      <link>https://oshea00.github.io/posts/agentic-codegen-part2/</link>
      <pubDate>Thu, 01 May 2025 00:00:00 +0000</pubDate>
      <guid>https://oshea00.github.io/posts/agentic-codegen-part2/</guid>
      <description>&lt;p&gt;&lt;figure class=&#34;align-center &#34;&gt;
    &lt;img loading=&#34;lazy&#34; src=&#34;images/agentflock.png#center&#34;/&gt; 
&lt;/figure&gt;

In this segment, I&amp;rsquo;ll generate many candidate applications using my experimental framework, &lt;a href=&#34;https://github.com/oshea00/codeagents&#34;&gt;CodeAgents&lt;/a&gt;, choosing from a set of models: GPT-4.1, Claude 3.7, and GPT-4o. Then, I&amp;rsquo;ll compare and contrast the solutions. Along the way, I&amp;rsquo;ll present some ideas and tips on improving AI-generated code in ways that generally translate to other tools and frameworks.&lt;/p&gt;
&lt;p&gt;It isn&amp;rsquo;t easy to score how good an AI-coded solution is. Of the possible metrics, code complexity might not be as meaningful as long as the AI understands the code, as would &amp;ldquo;maintainability,&amp;rdquo; as that&amp;rsquo;s based on human limitations; the AI can refactor on the fly. Test coverage is a good metric as it measures how well the AI-generated test suite covers the code.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Vibecoding an Agentic Coder - Part 1</title>
      <link>https://oshea00.github.io/posts/agentic-codegen-part1/</link>
      <pubDate>Sun, 27 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://oshea00.github.io/posts/agentic-codegen-part1/</guid>
      <description>&lt;p&gt;&lt;figure class=&#34;align-center &#34;&gt;
    &lt;img loading=&#34;lazy&#34; src=&#34;images/agentengineer_3_1_aspect_ratio.png#center&#34;/&gt; 
&lt;/figure&gt;

I&amp;rsquo;ve tried Cursor, Replit, Lovable, and Bolt with varying degrees of success and found recurring themes in the use of these tools that require &amp;ldquo;vibing&amp;rdquo; until you arrive at a finished, hopefully working, result. Whether the result is good can sometimes be in the eye of the beholder.&lt;/p&gt;
&lt;p&gt;I’ve also become fascinated by how these tools will change the way programmers think about code and its organization — how many rules will be thrown completely out the window and how, oddly, the new rules will harken back to the early days of programming before Google and the Internet.&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLMs At The Command Line - Part 1</title>
      <link>https://oshea00.github.io/posts/aichat-part1/</link>
      <pubDate>Sat, 18 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://oshea00.github.io/posts/aichat-part1/</guid>
      <description>&lt;figure class=&#34;align-center &#34;&gt;
    &lt;img loading=&#34;lazy&#34; src=&#34;images/cartoon_terminal.png#center&#34;/&gt; 
&lt;/figure&gt;

&lt;p&gt;If you are a command-line fan and want to experiment with large language models (LLM), you will love &lt;a href=&#34;https://github.com/sigoden/aichat&#34;&gt;&lt;code&gt;AiChat&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;There are many popular graphical front ends for working with LLMs, such as OpenAI&amp;rsquo;s ChatGPT, and Anthropic&amp;rsquo;s Claude, but get ready for this little powerhouse for CLI lovers as it has many advanced and useful features.&lt;/p&gt;
&lt;p&gt;One such feature is an easy-to-use, out-of-the-box RAG feature (Retrieval Augmented Generation) useful for searching existing content. I&amp;rsquo;ve put together a small demo here that shows how easy it can be to use in a pinch. There are many use cases where such an approach is just the right size.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Experimenting with Agentic AI Tooling: My Journey Through the Cutting Edge</title>
      <link>https://oshea00.github.io/posts/agentic-ai-tooling-pains/</link>
      <pubDate>Mon, 30 Dec 2024 00:00:00 +0000</pubDate>
      <guid>https://oshea00.github.io/posts/agentic-ai-tooling-pains/</guid>
      <description>&lt;figure class=&#34;align-center &#34;&gt;
    &lt;img loading=&#34;lazy&#34; src=&#34;images/cutecomputereditor.png#center&#34;/&gt; 
&lt;/figure&gt;

&lt;p&gt;The first time I fired up an MCP (Model Context Protocol) server plugin, &amp;ldquo;Agent,&amp;rdquo; I was excited to see it registered in Claude Desktop but immediately annoyed by the errors that popped up. I didn&amp;rsquo;t expect a smooth experience in my encounter with the future of Agentic AI, but I found many configuration tweaks, clunky debugging tools, and broken dependencies along the way. It was a stark reminder that we&amp;rsquo;re in the early days, and there&amp;rsquo;s a lot of ground to cover before Agents become seamless collaborators.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Navigating the Fragmented Landscape of Agentic AI Tools</title>
      <link>https://oshea00.github.io/posts/agentic-ai-fragmentation/</link>
      <pubDate>Sun, 15 Dec 2024 00:00:00 +0000</pubDate>
      <guid>https://oshea00.github.io/posts/agentic-ai-fragmentation/</guid>
      <description>&lt;figure class=&#34;align-center &#34;&gt;
    &lt;img loading=&#34;lazy&#34; src=&#34;images/agentengineer_3_1_aspect_ratio.png#center&#34;/&gt; 
&lt;/figure&gt;

&lt;p&gt;Agentic AI, with its promise of creating systems capable of autonomous reasoning and action, has been a hotbed of innovation
in the AI community. Tools from OpenAI, LangChain, and Microsoft are spearheading this new wave, each offering unique
features and capabilities. However, the lack of standardization in this ecosystem presents significant challenges to developers,
researchers, and organizations eager to adopt these technologies.&lt;/p&gt;
&lt;h2 id=&#34;the-current-state-of-agentic-ai-tools&#34;&gt;The Current State of Agentic AI Tools&lt;/h2&gt;
&lt;p&gt;The diversity of agentic AI tools is both a strength and a weakness. On one hand, it fosters creativity and innovation as
developers explore various approaches to building autonomous systems. On the other hand, the fragmented landscape leads to:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Classify With Confidence</title>
      <link>https://oshea00.github.io/posts/classify-with-confidence/</link>
      <pubDate>Sat, 02 Nov 2024 00:00:00 +0000</pubDate>
      <guid>https://oshea00.github.io/posts/classify-with-confidence/</guid>
      <description>&lt;p&gt;&lt;figure class=&#34;align-center &#34;&gt;
    &lt;img loading=&#34;lazy&#34; src=&#34;images/cutepredictioncartoon.png#center&#34;/&gt; 
&lt;/figure&gt;

Large foundation models like GPT can classify text according to a well-crafted prompt instruction, and it&amp;rsquo;s remarkable how well they can do this, considering there has been no explicit training with labeled datasets. This has traditionally been done using machine learning models and logistic regression techniques.&lt;/p&gt;
&lt;p&gt;However, with generative model classification, we lose the &amp;lsquo;confidence level&amp;rsquo; or the probability score of the prediction available in logistic regression. Traditional models like logistic regression provide a probability score for each class, indicating the model&amp;rsquo;s confidence level in its predictions. This confidence score is not just valuable; it&amp;rsquo;s essential for decision-making, as it helps users gauge how confident the model is about its classifications. While generative model responses may align well with the intended classification, we don&amp;rsquo;t directly get an explicit probability for each class. This can be a limitation, particularly in high-stakes applications where knowing the model&amp;rsquo;s confidence level is crucial.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Comparing Prompt Results - A Rose By Any Other Name</title>
      <link>https://oshea00.github.io/posts/a-rose-by-any-other-name/</link>
      <pubDate>Tue, 20 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://oshea00.github.io/posts/a-rose-by-any-other-name/</guid>
      <description>&lt;p&gt;&lt;figure class=&#34;align-center &#34;&gt;
    &lt;img loading=&#34;lazy&#34; src=&#34;images/androidrose.png#center&#34;/&gt; 
&lt;/figure&gt;

You might want to test an expected response from a prompt sent to a large language model, but string comparisons will not help you. The inherent variability in large language model (LLM) responses will require you to find new ways to compare generated prompt results.&lt;/p&gt;
&lt;p&gt;There are a few reasons why a generated prompt result will not exactly match a prior result: the prompt itself may have changed, the model parameters may have changed, or the model&amp;rsquo;s inherent variability may inject a small amount of change in the results.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Scaling OpenAI With AsyncOpenAI</title>
      <link>https://oshea00.github.io/posts/async-openai/</link>
      <pubDate>Sun, 07 Jul 2024 00:00:00 +0000</pubDate>
      <guid>https://oshea00.github.io/posts/async-openai/</guid>
      <description>&lt;p&gt;As I stood outside and looked at the neighborhood wasteland that post-July 4th left behind, the whiff of gunpowder still hanging in the air, I felt a burst of good neighbor energy flow through me, so I grabbed a broom. Sweeping up the street gave me time to think about the other chores I had for the day, including the writing of a new blog post, and I began to wonder how I could use ChatGPT to help me speed some things up.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Transformers -  Positional Encoding</title>
      <link>https://oshea00.github.io/posts/transformers-positional-encoding/</link>
      <pubDate>Mon, 27 May 2024 00:00:00 +0000</pubDate>
      <guid>https://oshea00.github.io/posts/transformers-positional-encoding/</guid>
      <description>&lt;p&gt;Since transformer input is processed in parallel rather than serially, it is necessary to encode the relative positions of the input sequence of tokens in some way. The positional encoding in the transformer model uses sinusoidal functions to create a unique encoding for each position.&lt;/p&gt;
&lt;p&gt;In working through the article on Transformers, as described in the original paper &lt;a href=&#34;https://arxiv.org/pdf/1706.03762&#34;&gt;&amp;ldquo;Attention is All You Need&amp;rdquo; by Vaswani et al.&lt;/a&gt;, the following formulas are used to encode the PE tensor values:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Fine-tuning Llama3</title>
      <link>https://oshea00.github.io/posts/finetuning-llama3-8b/</link>
      <pubDate>Sat, 11 May 2024 00:00:00 +0000</pubDate>
      <guid>https://oshea00.github.io/posts/finetuning-llama3-8b/</guid>
      <description>&lt;p&gt;Since Llama3 was released, the &lt;a href=&#34;https://pytorch.org/torchtune/stable/tutorials/llama3.html&#34;&gt;PyTorch llama3&lt;/a&gt; documentation has a few glitches pointing at configurations in torchtune that are still referencing Llama2. &lt;a href=&#34;https://llama.meta.com/docs/how-to-guides/fine-tuning/&#34;&gt;The meta website&lt;/a&gt; is a little more up-to-date, but the documentation is a little light on details. So, I
wrote this article to bring everything together.&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;You&amp;rsquo;ll want to use Python 3.11 &lt;a href=&#34;https://github.com/pytorch/pytorch/issues/120233&#34;&gt;until Torch compile supports Python 3.12&lt;/a&gt; , and I recommend setting up a virtual environment for this using &lt;code&gt;venv&lt;/code&gt; or &lt;code&gt;pipenv&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Install &lt;a href=&#34;https://pytorch.org/torchtune/stable/install.html#install-label&#34;&gt;torchtune&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install torchtune
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Install &lt;a href=&#34;https://github.com/EleutherAI/lm-evaluation-harness&#34;&gt;EleutherAI&amp;rsquo;s Evaluation Harness&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pip install &lt;span class=&#34;nv&#34;&gt;lm_eval&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;==&lt;/span&gt;0.4.*
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;download-llama3-8b-model&#34;&gt;Download Llama3-8B model&lt;/h2&gt;
&lt;p&gt;You will need to get access to Llama3 via instructions on the &lt;a href=&#34;https://github.com/meta-llama/llama3/blob/main/README.md&#34;&gt;official Meta Llama3&lt;/a&gt; page. You will also need your Hugging Face token setup from &lt;a href=&#34;https://huggingface.co/settings/tokens&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>OpenAI Python API Compatibility</title>
      <link>https://oshea00.github.io/posts/openai-compatible-apis/</link>
      <pubDate>Thu, 09 May 2024 00:00:00 +0000</pubDate>
      <guid>https://oshea00.github.io/posts/openai-compatible-apis/</guid>
      <description>&lt;p&gt;An increasing number of open-sourced generative AI large language models (LLM) are being hosted behind an OpenAI API-compatible endpoint or have tools that offer an OpenAI API. The Python library for accessing OpenAI is just a REST client, and the library provides a way to specify the URL and an API key, as well as the model being offered by the provider.&lt;/p&gt;
&lt;p&gt;Here are a few examples of how the OpenAI library is used with other open-source models.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
